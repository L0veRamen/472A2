{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP 472 Assignment 2\n",
    "## Team: RoboCops\n",
    "### Team Members:\n",
    "- Rongxi Meng (40045067)\n",
    "- Chen Qian (27867808)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Task 1: Evaluation of the word2vec-google-news-300 Pre-trained Model\n",
    "In this first experiment, you will use the pre-trained Word2Vec model called word2vec-google-news-300 to \n",
    "compute the closest synonym for each word in the dataset.\n",
    " First, use gensim.downloader.load to load th \n",
    "word2vec-google-news-300 pre-trained embedding model. Then use the similarity meth d from Gensim  o\n",
    "compute the cosine similarity between 2 embeddings (2 vectors) and find the closest synonym to the questioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "import pandas as pd\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your CSV file into a pandas DataFrame\n",
    "df = pd.read_csv('./datasets/synonym.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>enormously</td>\n",
       "      <td>tremendously</td>\n",
       "      <td>appropriately</td>\n",
       "      <td>uniquely</td>\n",
       "      <td>tremendously</td>\n",
       "      <td>decidedly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>provisions</td>\n",
       "      <td>stipulations</td>\n",
       "      <td>stipulations</td>\n",
       "      <td>interrelations</td>\n",
       "      <td>jurisdictions</td>\n",
       "      <td>interpretations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>haphazardly</td>\n",
       "      <td>randomly</td>\n",
       "      <td>dangerously</td>\n",
       "      <td>densely</td>\n",
       "      <td>randomly</td>\n",
       "      <td>linearly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prominent</td>\n",
       "      <td>conspicuous</td>\n",
       "      <td>battered</td>\n",
       "      <td>ancient</td>\n",
       "      <td>mysterious</td>\n",
       "      <td>conspicuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zenith</td>\n",
       "      <td>pinnacle</td>\n",
       "      <td>completion</td>\n",
       "      <td>pinnacle</td>\n",
       "      <td>outset</td>\n",
       "      <td>decline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>fashion</td>\n",
       "      <td>manner</td>\n",
       "      <td>ration</td>\n",
       "      <td>fathom</td>\n",
       "      <td>craze</td>\n",
       "      <td>manner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>marketed</td>\n",
       "      <td>sold</td>\n",
       "      <td>frozen</td>\n",
       "      <td>sold</td>\n",
       "      <td>sweetened</td>\n",
       "      <td>diluted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>bigger</td>\n",
       "      <td>larger</td>\n",
       "      <td>steadier</td>\n",
       "      <td>closer</td>\n",
       "      <td>larger</td>\n",
       "      <td>better</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>roots</td>\n",
       "      <td>origins</td>\n",
       "      <td>origins</td>\n",
       "      <td>rituals</td>\n",
       "      <td>cure</td>\n",
       "      <td>function</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>normally</td>\n",
       "      <td>ordinarily</td>\n",
       "      <td>haltingly</td>\n",
       "      <td>ordinarily</td>\n",
       "      <td>permanently</td>\n",
       "      <td>periodically</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       question        answer              0               1              2  \\\n",
       "0    enormously  tremendously  appropriately        uniquely   tremendously   \n",
       "1    provisions  stipulations   stipulations  interrelations  jurisdictions   \n",
       "2   haphazardly      randomly    dangerously         densely       randomly   \n",
       "3     prominent   conspicuous       battered         ancient     mysterious   \n",
       "4        zenith      pinnacle     completion        pinnacle         outset   \n",
       "..          ...           ...            ...             ...            ...   \n",
       "75      fashion        manner         ration          fathom          craze   \n",
       "76     marketed          sold         frozen            sold      sweetened   \n",
       "77       bigger        larger       steadier          closer         larger   \n",
       "78        roots       origins        origins         rituals           cure   \n",
       "79     normally    ordinarily      haltingly      ordinarily    permanently   \n",
       "\n",
       "                  3  \n",
       "0         decidedly  \n",
       "1   interpretations  \n",
       "2          linearly  \n",
       "3       conspicuous  \n",
       "4           decline  \n",
       "..              ...  \n",
       "75           manner  \n",
       "76          diluted  \n",
       "77           better  \n",
       "78         function  \n",
       "79     periodically  \n",
       "\n",
       "[80 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to find the closest synonym using the word2vec model and label the prediction\n",
    "def find_synonym_and_label(row, model):\n",
    "    question_word = row['question']\n",
    "    correct_answer = row['answer']\n",
    "    choices = row[['0', '1', '2', '3']].values\n",
    "    synonym_found = False\n",
    "    label = 'guess'\n",
    "    \n",
    "    # Check if the question word is in the model's vocabulary\n",
    "    if question_word in model.key_to_index:\n",
    "        # Check each choice to see if it's in the model's vocabulary\n",
    "        valid_choices = [choice for choice in choices if choice in model.key_to_index]\n",
    "        if valid_choices:\n",
    "            # Use the model to predict the most similar word from the valid choices\n",
    "            most_similar = model.most_similar_to_given(question_word, valid_choices)\n",
    "            synonym_found = True\n",
    "            # Determine if the model's choice is correct\n",
    "            label = 'correct' if most_similar == correct_answer else 'wrong'\n",
    "    \n",
    "    # Return the model's choice if a valid synonym was found, otherwise None\n",
    "    predicted_synonym = most_similar if synonym_found else None\n",
    "    return pd.Series([predicted_synonym, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the DataFrame\n",
    "df[['predicted_synonym', 'label']] = df.apply(lambda row: find_synonym_and_label(row, word2vec_model), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select and order the columns as specified\n",
    "df_output = df[['question', 'answer', 'predicted_synonym', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame with the predicted synonyms and labels to a CSV file\n",
    "output_file_path = './output/task_1/word2vec-google-news-300-details.csv'\n",
    "df_output.to_csv(output_file_path, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      question        answer predicted_synonym    label\n",
      "0   enormously  tremendously      tremendously  correct\n",
      "1   provisions  stipulations      stipulations  correct\n",
      "2  haphazardly      randomly          randomly  correct\n",
      "3    prominent   conspicuous       conspicuous  correct\n",
      "4       zenith      pinnacle          pinnacle  correct\n"
     ]
    }
   ],
   "source": [
    "print(df_output.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of correct labels\n",
    "num_correct = (df_output['label'] == 'correct').sum()\n",
    "\n",
    "# Calculate the number of questions answered without guessing\n",
    "num_answered = (df_output['label'] != 'guess').sum()\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = num_correct / num_answered if num_answered > 0 else 0\n",
    "\n",
    "# Get the size of the vocabulary of the model\n",
    "vocab_size = len(word2vec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for the analysis.csv file\n",
    "task_1_analysis_data = {\n",
    "    'model_name': 'word2vec-google-news-300',\n",
    "    'vocab_size': vocab_size,\n",
    "    'num_correct': num_correct,\n",
    "    'num_answered': num_answered,\n",
    "    'accuracy': accuracy\n",
    "}\n",
    "\n",
    "# Convert the analysis data to a DataFrame\n",
    "df_task_1_analysis = pd.DataFrame([task_1_analysis_data])\n",
    "\n",
    "# Save the analysis DataFrame to a CSV file\n",
    "df_task_1_analysis.to_csv('./output/task_1/analysis.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>vocab_size</th>\n",
       "      <th>num_correct</th>\n",
       "      <th>num_answered</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>word2vec-google-news-300</td>\n",
       "      <td>3000000</td>\n",
       "      <td>70</td>\n",
       "      <td>79</td>\n",
       "      <td>0.886076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model_name  vocab_size  num_correct  num_answered  accuracy\n",
       "0  word2vec-google-news-300     3000000           70            79  0.886076"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_task_1_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Task 2: Comparison with Other Pre-trained Models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to predict synonyms using a model and evaluate the accuracy\n",
    "def predict_and_evaluate(model_name, model, df):\n",
    "    def get_prediction(row):\n",
    "        question_word = row['question']\n",
    "        choices = [row[str(i)] for i in range(4)]\n",
    "        if question_word in model.key_to_index:\n",
    "            valid_choices = [choice for choice in choices if choice in model.key_to_index]\n",
    "            if valid_choices:\n",
    "                return model.most_similar_to_given(question_word, valid_choices), 'correct' if row['answer'] in valid_choices else 'wrong'\n",
    "        return None, 'guess'\n",
    "    \n",
    "    # Add predictions and labels to the DataFrame\n",
    "    df[[f'predicted_synonym_{model_name}', f'label_{model_name}']] = df.apply(get_prediction, axis=1, result_type='expand')\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    correct = df[f'label_{model_name}'] == 'correct'\n",
    "    guessed = df[f'label_{model_name}'] != 'guess'\n",
    "    accuracy = correct.sum() / guessed.sum() if guessed.sum() > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'vocab_size': len(model.key_to_index),\n",
    "        'num_correct': correct.sum(),\n",
    "        'num_answered': guessed.sum(),\n",
    "        'accuracy': accuracy\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model names according to the gensim downloader API\n",
    "model_names = ['glove-wiki-gigaword-300', 'fasttext-wiki-news-subwords-300', 'glove-twitter-25', 'glove-twitter-50']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained models (placeholders for the actual model names)\n",
    "models = {\n",
    "    'glove-wiki-gigaword-300': api.load(model_names[0]),\n",
    "    'fasttext-wiki-news-subwords-300': api.load(model_names[1]),\n",
    "    'glove-twitter-25': api.load(model_names[2]),\n",
    "    'glove-twitter-50': api.load(model_names[3]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate each model\n",
    "results = [df_task_1_analysis.iloc[0].to_dict()]  # Start with the analysis from task 1\n",
    "for model_name, model in models.items():\n",
    "    results.append(predict_and_evaluate(model_name, model, df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the results to a DataFrame and save to CSV\n",
    "df_task_2_analysis = pd.DataFrame(results)\n",
    "df_task_2_analysis.to_csv('./output/task_2/analysis.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>vocab_size</th>\n",
       "      <th>num_correct</th>\n",
       "      <th>num_answered</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>word2vec-google-news-300</td>\n",
       "      <td>3000000</td>\n",
       "      <td>70</td>\n",
       "      <td>79</td>\n",
       "      <td>0.886076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>glove-wiki-gigaword-300</td>\n",
       "      <td>400000</td>\n",
       "      <td>79</td>\n",
       "      <td>80</td>\n",
       "      <td>0.987500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fasttext-wiki-news-subwords-300</td>\n",
       "      <td>999999</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>glove-twitter-25</td>\n",
       "      <td>1193514</td>\n",
       "      <td>77</td>\n",
       "      <td>78</td>\n",
       "      <td>0.987179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>glove-twitter-50</td>\n",
       "      <td>1193514</td>\n",
       "      <td>77</td>\n",
       "      <td>78</td>\n",
       "      <td>0.987179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model_name  vocab_size  num_correct  num_answered  \\\n",
       "0         word2vec-google-news-300     3000000           70            79   \n",
       "1          glove-wiki-gigaword-300      400000           79            80   \n",
       "2  fasttext-wiki-news-subwords-300      999999           80            80   \n",
       "3                 glove-twitter-25     1193514           77            78   \n",
       "4                 glove-twitter-50     1193514           77            78   \n",
       "\n",
       "   accuracy  \n",
       "0  0.886076  \n",
       "1  0.987500  \n",
       "2  1.000000  \n",
       "3  0.987179  \n",
       "4  0.987179  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_task_2_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Task 3: Train your Own Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import string\n",
    "import os\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Split text into sentences\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    # Tokenize each sentence into words and remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    processed_sentences = [[word for word in nltk.word_tokenize(sentence) if word not in stop_words] for sentence in sentences]\n",
    "    return processed_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing your book files\n",
    "book_directory = './books/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and preprocess each book\n",
    "all_sentences = []\n",
    "for filename in os.listdir(book_directory):\n",
    "    if filename.endswith('.txt'):\n",
    "        file_path = os.path.join(book_directory, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "            all_sentences.extend(preprocess_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a DataFrame with the analysis result values in it\n",
    "df_task_3_analysis = df_task_2_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Window sizes and embedding sizes\n",
    "window_sizes = [5, 10]  # W1, W2\n",
    "embedding_sizes = [100, 200]  # E5, E6\n",
    "model_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the df for model testing\n",
    "df = pd.read_csv('./datasets/synonym.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_evaluate_task_3(model_name, model, df):\n",
    "    def get_prediction(row):\n",
    "        question_word = row['question']\n",
    "        choices = [row[str(i)] for i in range(4)]\n",
    "        if question_word in model.wv.key_to_index:  # Accessing the vocabulary\n",
    "            valid_choices = [choice for choice in choices if choice in model.wv.key_to_index]\n",
    "            if valid_choices:\n",
    "                most_similar_word = model.wv.most_similar_to_given(question_word, valid_choices)\n",
    "                return most_similar_word, 'correct' if most_similar_word == row['answer'] else 'wrong'\n",
    "        return None, 'guess'\n",
    "    \n",
    "    df[[f'predicted_synonym_{model_name}', f'label_{model_name}']] = df.apply(get_prediction, axis=1, result_type='expand')\n",
    "    correct = df[f'label_{model_name}'] == 'correct'\n",
    "    guessed = df[f'label_{model_name}'] != 'guess'\n",
    "    accuracy = correct.sum() / guessed.sum() if guessed.sum() > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'vocab_size': len(model.wv.key_to_index),\n",
    "        'num_correct': correct.sum(),\n",
    "        'num_answered': guessed.sum(),\n",
    "        'accuracy': accuracy\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Word2Vec models with different configurations\n",
    "for embedding_size in window_sizes:\n",
    "    for  window_size in embedding_sizes:\n",
    "        model = Word2Vec(sentences=all_sentences, vector_size=embedding_size, window=window_size, min_count=1, workers=4)\n",
    "        model_name = f\"Word2Vec-E{embedding_size}-W{window_size}\"\n",
    "\n",
    "        # Evaluate the model using your predict_and_evaluate_task_3 function\n",
    "        results = predict_and_evaluate_task_3(model_name, model, df)\n",
    "\n",
    "        # Append the results to the model_results list\n",
    "        model_results.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the results\n",
    "df_model_results = pd.DataFrame(model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the results of these models to df_task_3_analysis DataFrame\n",
    "df_task_3_analysis = pd.concat([df_task_3_analysis, df_model_results], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_3_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "print(api.base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(df_task_3_analysis['model_name'], df_task_3_analysis['accuracy'], color='skyblue')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(rotation=-45)\n",
    "plt.title('Comparison of Word2Vec Model Performances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: Performance Comparison of Word2Vec Models\n",
    "\n",
    "### Key Observations:\n",
    "- Models trained on the Gutenberg corpus (`Word2Vec-E5-W100`, `Word2Vec-E5-W200`, etc.) showed varying accuracy, with none exceeding 35%. This contrasts with higher accuracies observed in pre-trained models like `word2vec-google-news-300` and `glove-wiki-gigaword-300`.\n",
    "- Larger vocabulary sizes in the pre-trained models contributed to their superior performance, highlighting the importance of diverse training data.\n",
    "- The variation in accuracy between different window sizes and embedding dimensions in the Gutenberg-trained models suggests that these parameters significantly impact the model's ability to capture semantic relationships.\n",
    "\n",
    "### Speculations on Model Performance:\n",
    "- **Pre-trained Models** performed better likely due to more extensive and varied training data, leading to more robust word embeddings.\n",
    "- **Custom Gutenberg Models** had lower accuracy, possibly due to limited context and diversity in the training dataset.\n",
    "- **Parameter Influence**: The choice of window size and embedding dimensions appears to be crucial, with each configuration offering different strengths, depending on the nature of the text and the task at hand.\n",
    "\n",
    "Overall, the analysis underscores the importance of rich and varied training data, along with careful tuning of model parameters, in building effective Word2Vec models for natural language processing tasks.\n",
    "e."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
